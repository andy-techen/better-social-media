{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\cameron milne\\appdata\\roaming\\python\\python38\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: textblob in c:\\programdata\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1; python_version >= \"3\" in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (0.17.0)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2020.10.15)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.50.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.19.2)\n",
      "Requirement already satisfied: sklearn in c:\\programdata\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim --user\n",
    "!pip install textblob\n",
    "!pip install scikit-learn --user\n",
    "!pip install sklearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.0.1\n",
      "  Using cached scikit_learn-1.0.1-cp38-cp38-win_amd64.whl (7.2 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\scikit_learn-0.23.2.dist-info\\\\COPYING'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.14.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.1) (1.19.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.1) (0.17.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.1) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.1) (2.1.0)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.23.2\n",
      "    Uninstalling scikit-learn-0.23.2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.1\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Cameron\n",
      "[nltk_data]     Milne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Cameron\n",
      "[nltk_data]     Milne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#Timing\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Word Embeddings\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_tweets = pd.read_csv('scored_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scored_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'text', 'username', 'screen_name', 'verified',\n",
       "       'followers_count', 'TOXICITY', 'INSULT', 'PROFANITY', 'THREAT',\n",
       "       'SEXUALLY_EXPLICIT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>SEXUALLY_EXPLICIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOXICITY</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945739</td>\n",
       "      <td>0.921274</td>\n",
       "      <td>0.572428</td>\n",
       "      <td>0.700610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSULT</th>\n",
       "      <td>0.945739</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827742</td>\n",
       "      <td>0.464412</td>\n",
       "      <td>0.542923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROFANITY</th>\n",
       "      <td>0.921274</td>\n",
       "      <td>0.827742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.442225</td>\n",
       "      <td>0.758937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THREAT</th>\n",
       "      <td>0.572428</td>\n",
       "      <td>0.464412</td>\n",
       "      <td>0.442225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEXUALLY_EXPLICIT</th>\n",
       "      <td>0.700610</td>\n",
       "      <td>0.542923</td>\n",
       "      <td>0.758937</td>\n",
       "      <td>0.425812</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   TOXICITY    INSULT  PROFANITY    THREAT  SEXUALLY_EXPLICIT\n",
       "TOXICITY           1.000000  0.945739   0.921274  0.572428           0.700610\n",
       "INSULT             0.945739  1.000000   0.827742  0.464412           0.542923\n",
       "PROFANITY          0.921274  0.827742   1.000000  0.442225           0.758937\n",
       "THREAT             0.572428  0.464412   0.442225  1.000000           0.425812\n",
       "SEXUALLY_EXPLICIT  0.700610  0.542923   0.758937  0.425812           1.000000"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_tweets.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>SEXUALLY_EXPLICIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>created_at</td>\n",
       "      <td>text</td>\n",
       "      <td>username</td>\n",
       "      <td>screen_name</td>\n",
       "      <td>verified</td>\n",
       "      <td>followers_count</td>\n",
       "      <td>0.042518</td>\n",
       "      <td>0.015740</td>\n",
       "      <td>0.037332</td>\n",
       "      <td>0.043029</td>\n",
       "      <td>0.040426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thu Dec 02 15:39:21 +0000 2021</td>\n",
       "      <td>This needs to become a real thing. I wanna see...</td>\n",
       "      <td>GhostFedoraTWEET</td>\n",
       "      <td>GhostyRBLX</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>0.552407</td>\n",
       "      <td>0.666591</td>\n",
       "      <td>0.313011</td>\n",
       "      <td>0.431656</td>\n",
       "      <td>0.100750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thu Dec 02 15:39:21 +0000 2021</td>\n",
       "      <td>@ENHYPEN_members love u more jake</td>\n",
       "      <td>aii.laa</td>\n",
       "      <td>jayenaii</td>\n",
       "      <td>False</td>\n",
       "      <td>85</td>\n",
       "      <td>0.084299</td>\n",
       "      <td>0.061555</td>\n",
       "      <td>0.109649</td>\n",
       "      <td>0.069504</td>\n",
       "      <td>0.119767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0                      created_at   \n",
       "1  Thu Dec 02 15:39:21 +0000 2021   \n",
       "2  Thu Dec 02 15:39:21 +0000 2021   \n",
       "\n",
       "                                                text          username  \\\n",
       "0                                               text          username   \n",
       "1  This needs to become a real thing. I wanna see...  GhostFedoraTWEET   \n",
       "2                  @ENHYPEN_members love u more jake           aii.laa   \n",
       "\n",
       "   screen_name  verified  followers_count  TOXICITY    INSULT  PROFANITY  \\\n",
       "0  screen_name  verified  followers_count  0.042518  0.015740   0.037332   \n",
       "1   GhostyRBLX     False               28  0.552407  0.666591   0.313011   \n",
       "2     jayenaii     False               85  0.084299  0.061555   0.109649   \n",
       "\n",
       "     THREAT  SEXUALLY_EXPLICIT  \n",
       "0  0.043029           0.040426  \n",
       "1  0.431656           0.100750  \n",
       "2  0.069504           0.119767  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_tweets.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_tweets.dropna(subset=['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(tweets_array):\n",
    "    \n",
    "    \"\"\"\n",
    "    Take in an array of tweets, and return the processed tweets.\n",
    "    remove stopwords, usernames, punctuation, and words with length of 1\n",
    "    \"\"\"\n",
    "    processed_array = []\n",
    "    \n",
    "    for tweet in tqdm(tweets_array):\n",
    "        processed_punc = re.sub('[^@a-zA-Z ]', '', tweet)  # remove punctuation\n",
    "        processed = re.sub('https\\S+|@\\S+|\\b\\w{,1}\\b', '', processed_punc)  # remove https, usernames, len(word) < 1\n",
    "        words = word_tokenize(processed)\n",
    "        tokens_without_sw = [word for word in words if not word in stopwords.words()]\n",
    "        sentence = ' '.join(tokens_without_sw)\n",
    "        stemmed_sentence = p.stem_sentence(sentence)\n",
    "        processed_array.append(stemmed_sentence)\n",
    "    \n",
    "    return processed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1962/1962 [06:02<00:00,  5.41it/s]\n"
     ]
    }
   ],
   "source": [
    "scored_tweets['processed'] = preprocessing(scored_tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# #tokenizes every tweet\n",
    "# tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "# scored_tweets['processed'] = scored_tweets['text'].apply(tokenizer.tokenize)\n",
    "# scored_tweets['processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords \n",
    "\n",
    "# #Widely used stopword library\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# #gets rid of numbers\n",
    "# stop_words.update([str(x) for x in np.arange(10)])\n",
    "\n",
    "# #apply to tokens\n",
    "# scored_tweets['processed'] = scored_tweets.processed.apply(lambda x: [i for i in x if not i in stop_words])\n",
    "# scored_tweets['processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scored_tweets['processed'] = [' '.join(l) for l in scored_tweets['processed']]\n",
    "# scored_tweets['processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Scores to Round Numbers\n",
    "scored_tweets['TOXICITY'] = round(scored_tweets['TOXICITY'] * 10, 0)\n",
    "scored_tweets['PROFANITY'] = round(scored_tweets['PROFANITY'] * 10, 0)\n",
    "scored_tweets['SEXUALLY_EXPLICIT'] = round(scored_tweets['SEXUALLY_EXPLICIT'] * 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>SEXUALLY_EXPLICIT</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>created_at</td>\n",
       "      <td>text</td>\n",
       "      <td>username</td>\n",
       "      <td>screen_name</td>\n",
       "      <td>verified</td>\n",
       "      <td>followers_count</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thu Dec 02 15:39:21 +0000 2021</td>\n",
       "      <td>This needs to become a real thing. I wanna see...</td>\n",
       "      <td>GhostFedoraTWEET</td>\n",
       "      <td>GhostyRBLX</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.666591</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.431656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>thi need becom real thing i wan see full us sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thu Dec 02 15:39:21 +0000 2021</td>\n",
       "      <td>@ENHYPEN_members love u more jake</td>\n",
       "      <td>aii.laa</td>\n",
       "      <td>jayenaii</td>\n",
       "      <td>False</td>\n",
       "      <td>85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.061555</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.069504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>love jake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thu Dec 02 15:39:21 +0000 2021</td>\n",
       "      <td>@ENHYPEN_members i hope you'll get a good rest...</td>\n",
       "      <td>ً</td>\n",
       "      <td>igpshluv</td>\n",
       "      <td>False</td>\n",
       "      <td>2337</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.103891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.506230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hope youll get good rest fight tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thu Dec 02 15:39:21 +0000 2021</td>\n",
       "      <td>@Mal_DuBois It was dragged across on a dinghy...</td>\n",
       "      <td>Gavlar87</td>\n",
       "      <td>gavlar87</td>\n",
       "      <td>False</td>\n",
       "      <td>149</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.123806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.298187</td>\n",
       "      <td>2.0</td>\n",
       "      <td>it drag across dinghi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0                      created_at   \n",
       "1  Thu Dec 02 15:39:21 +0000 2021   \n",
       "2  Thu Dec 02 15:39:21 +0000 2021   \n",
       "3  Thu Dec 02 15:39:21 +0000 2021   \n",
       "4  Thu Dec 02 15:39:21 +0000 2021   \n",
       "\n",
       "                                                text          username  \\\n",
       "0                                               text          username   \n",
       "1  This needs to become a real thing. I wanna see...  GhostFedoraTWEET   \n",
       "2                  @ENHYPEN_members love u more jake           aii.laa   \n",
       "3  @ENHYPEN_members i hope you'll get a good rest...                 ً   \n",
       "4   @Mal_DuBois It was dragged across on a dinghy...          Gavlar87   \n",
       "\n",
       "   screen_name  verified  followers_count  TOXICITY    INSULT  PROFANITY  \\\n",
       "0  screen_name  verified  followers_count       0.0  0.015740        0.0   \n",
       "1   GhostyRBLX     False               28       6.0  0.666591        3.0   \n",
       "2     jayenaii     False               85       1.0  0.061555        1.0   \n",
       "3     igpshluv     False             2337       1.0  0.103891        1.0   \n",
       "4     gavlar87     False              149       2.0  0.123806        1.0   \n",
       "\n",
       "     THREAT  SEXUALLY_EXPLICIT  \\\n",
       "0  0.043029                0.0   \n",
       "1  0.431656                1.0   \n",
       "2  0.069504                1.0   \n",
       "3  0.506230                1.0   \n",
       "4  0.298187                2.0   \n",
       "\n",
       "                                           processed  \n",
       "0                                               text  \n",
       "1  thi need becom real thing i wan see full us sp...  \n",
       "2                                          love jake  \n",
       "3            hope youll get good rest fight tomorrow  \n",
       "4                              it drag across dinghi  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     993\n",
       "2.0     370\n",
       "3.0     128\n",
       "0.0     126\n",
       "4.0      82\n",
       "9.0      69\n",
       "5.0      63\n",
       "7.0      49\n",
       "6.0      46\n",
       "8.0      31\n",
       "10.0      5\n",
       "Name: TOXICITY, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirms range of values for labels\n",
    "scored_tweets['TOXICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df=scored_tweets, feature='processed', label='TOXICITY'):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    train_data, test_data = train_test_split(df, test_size=0.25, random_state=7)\n",
    "    X_train, X_test = np.asarray(train_data['processed']), np.asarray(test_data['processed'])\n",
    "    y_train, y_test = np.asarray(train_data[label]), np.asarray(test_data[label])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(df=scored_tweets, feature='processed', label='TOXICITY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(X_train, X_test):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    test_tfidf = vectorizer.transform(X_test)\n",
    "    \n",
    "    return train_tfidf, test_tfidf, vectorizer\n",
    "\n",
    "train_tfidf, test_tfidf, vectorizer = TFIDF(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open('PerspectiveAPI_vectorizer.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost_Classifier(feature_category):\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_data(label=feature_category)\n",
    "    train_tfidf, test_tfidf, _ = TFIDF(X_train, X_test)\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "    model.fit(train_tfidf, y_train)\n",
    "    \n",
    "    y_pred = model.predict(test_tfidf)\n",
    "    acc = accuracy_score(y_pred, y_test)\n",
    "    \n",
    "    return (acc, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:31:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.47046843177189407,\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "               gamma=0, gpu_id=-1, importance_type=None,\n",
       "               interaction_constraints='', learning_rate=0.300000012,\n",
       "               max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "               monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "               num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "               subsample=1, tree_method='exact', validate_parameters=1,\n",
       "               verbosity=None))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_results = XGBoost_Classifier('TOXICITY')\n",
    "toxicity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(toxicity_results[1], open('toxicity_xgb.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:31:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4419551934826884,\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "               gamma=0, gpu_id=-1, importance_type=None,\n",
       "               interaction_constraints='', learning_rate=0.300000012,\n",
       "               max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "               monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "               num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "               subsample=1, tree_method='exact', validate_parameters=1,\n",
       "               verbosity=None))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profanity_results = XGBoost_Classifier('PROFANITY')\n",
    "profanity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(profanity_results[1], open('profanity_xgb.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:31:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.49287169042769857,\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "               gamma=0, gpu_id=-1, importance_type=None,\n",
       "               interaction_constraints='', learning_rate=0.300000012,\n",
       "               max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "               monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "               num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "               subsample=1, tree_method='exact', validate_parameters=1,\n",
       "               verbosity=None))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexually_explicit_results = XGBoost_Classifier('SEXUALLY_EXPLICIT')\n",
    "sexually_explicit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(sexually_explicit_results[1], open('sexually_explicit_xgb.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
