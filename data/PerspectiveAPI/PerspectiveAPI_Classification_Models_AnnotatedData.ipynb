{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\cameron milne\\appdata\\roaming\\python\\python38\\site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: textblob in c:\\programdata\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1; python_version >= \"3\" in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.50.2)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (0.17.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2020.10.15)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: sklearn in c:\\programdata\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim --user\n",
    "!pip install textblob\n",
    "!pip install scikit-learn --user\n",
    "!pip install sklearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.0.1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\scikit_learn-0.23.2.dist-info\\\\COPYING'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached scikit_learn-1.0.1-cp38-cp38-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.1) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.1) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.1) (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.0.1) (1.19.2)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.23.2\n",
      "    Uninstalling scikit-learn-0.23.2:\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.1\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Cameron\n",
      "[nltk_data]     Milne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Cameron\n",
      "[nltk_data]     Milne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#Timing\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Word Embeddings\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_comments = pd.read_csv('AnnotatedData/RC_2017-01_scored.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_tweets = reddit_comments[['author', 'subreddit', 'body', 'toxicity', 'profanity', 'sexually_explicit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cameron Milne\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py:5039: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "scored_tweets.rename(columns={'toxicity': 'TOXICITY', 'profanity': 'PROFANITY', 'sexually_explicit': 'SEXUALLY_EXPLICIT'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'subreddit', 'body', 'TOXICITY', 'PROFANITY',\n",
       "       'SEXUALLY_EXPLICIT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>SEXUALLY_EXPLICIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOXICITY</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962363</td>\n",
       "      <td>0.655689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROFANITY</th>\n",
       "      <td>0.962363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEXUALLY_EXPLICIT</th>\n",
       "      <td>0.655689</td>\n",
       "      <td>0.659925</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   TOXICITY  PROFANITY  SEXUALLY_EXPLICIT\n",
       "TOXICITY           1.000000   0.962363           0.655689\n",
       "PROFANITY          0.962363   1.000000           0.659925\n",
       "SEXUALLY_EXPLICIT  0.655689   0.659925           1.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_tweets.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>SEXUALLY_EXPLICIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frantic_Mantid</td>\n",
       "      <td>awwnverts</td>\n",
       "      <td>Those eyes! I don't think I've ever seen a spi...</td>\n",
       "      <td>0.203826</td>\n",
       "      <td>0.126241</td>\n",
       "      <td>0.257775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I_LICK_PUPPIES</td>\n",
       "      <td>longboarding</td>\n",
       "      <td>I didn't even catch on... Lmao god damn it.</td>\n",
       "      <td>0.837652</td>\n",
       "      <td>0.919330</td>\n",
       "      <td>0.202414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCMRwill0956</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>I'll take it\\n</td>\n",
       "      <td>0.058286</td>\n",
       "      <td>0.029915</td>\n",
       "      <td>0.102896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author     subreddit  \\\n",
       "0  Frantic_Mantid     awwnverts   \n",
       "1  I_LICK_PUPPIES  longboarding   \n",
       "2    PCMRwill0956  pcmasterrace   \n",
       "\n",
       "                                                body  TOXICITY  PROFANITY  \\\n",
       "0  Those eyes! I don't think I've ever seen a spi...  0.203826   0.126241   \n",
       "1        I didn't even catch on... Lmao god damn it.  0.837652   0.919330   \n",
       "2                                     I'll take it\\n  0.058286   0.029915   \n",
       "\n",
       "   SEXUALLY_EXPLICIT  \n",
       "0           0.257775  \n",
       "1           0.202414  \n",
       "2           0.102896  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38406 entries, 0 to 38405\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   author             38406 non-null  object \n",
      " 1   subreddit          38406 non-null  object \n",
      " 2   body               38406 non-null  object \n",
      " 3   TOXICITY           38367 non-null  float64\n",
      " 4   PROFANITY          38367 non-null  float64\n",
      " 5   SEXUALLY_EXPLICIT  38367 non-null  float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "scored_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cameron Milne\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "scored_tweets.dropna(subset=['body'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(tweets_array):\n",
    "    \n",
    "    \"\"\"\n",
    "    Take in an array of tweets, and return the processed tweets.\n",
    "    remove stopwords, usernames, punctuation, and words with length of 1\n",
    "    \"\"\"\n",
    "    processed_array = []\n",
    "    \n",
    "    for tweet in tqdm(tweets_array):\n",
    "        processed_punc = re.sub('[^@a-zA-Z ]', '', tweet)  # remove punctuation\n",
    "        processed = re.sub('https\\S+|@\\S+|\\b\\w{,1}\\b', '', processed_punc)  # remove https, usernames, len(word) < 1\n",
    "        words = word_tokenize(processed)\n",
    "        tokens_without_sw = [word for word in words if not word in stopwords.words()]\n",
    "        sentence = ' '.join(tokens_without_sw)\n",
    "        stemmed_sentence = p.stem_sentence(sentence)\n",
    "        processed_array.append(stemmed_sentence)\n",
    "    \n",
    "    return processed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:31<00:00,  3.16it/s]\n"
     ]
    }
   ],
   "source": [
    "scored_tweets['processed'] = preprocessing(scored_tweets['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# #tokenizes every tweet\n",
    "# tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "# scored_tweets['processed'] = scored_tweets['text'].apply(tokenizer.tokenize)\n",
    "# scored_tweets['processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords \n",
    "\n",
    "# #Widely used stopword library\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# #gets rid of numbers\n",
    "# stop_words.update([str(x) for x in np.arange(10)])\n",
    "\n",
    "# #apply to tokens\n",
    "# scored_tweets['processed'] = scored_tweets.processed.apply(lambda x: [i for i in x if not i in stop_words])\n",
    "# scored_tweets['processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scored_tweets['processed'] = [' '.join(l) for l in scored_tweets['processed']]\n",
    "# scored_tweets['processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Scores to Round Numbers\n",
    "scored_tweets['TOXICITY'] = round(scored_tweets['TOXICITY'] * 10, 0)\n",
    "scored_tweets['PROFANITY'] = round(scored_tweets['PROFANITY'] * 10, 0)\n",
    "scored_tweets['SEXUALLY_EXPLICIT'] = round(scored_tweets['SEXUALLY_EXPLICIT'] * 10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>SEXUALLY_EXPLICIT</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frantic_Mantid</td>\n",
       "      <td>awwnverts</td>\n",
       "      <td>Those eyes! I don't think I've ever seen a spi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>those ey i dont think iv ever seen spider ey l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I_LICK_PUPPIES</td>\n",
       "      <td>longboarding</td>\n",
       "      <td>I didn't even catch on... Lmao god damn it.</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>i didnt even catch lmao god damn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCMRwill0956</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>I'll take it\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shermont</td>\n",
       "      <td>RocketLeagueExchange</td>\n",
       "      <td>What's ur gt il send a friend req... n il let ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>what ur gt send friend req let kno still moro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PandaBearShenyu</td>\n",
       "      <td>ffxiv</td>\n",
       "      <td>You.... should not be losing stacks to ES even...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>you lose stack es even run back forth without ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author             subreddit  \\\n",
       "0   Frantic_Mantid             awwnverts   \n",
       "1   I_LICK_PUPPIES          longboarding   \n",
       "2     PCMRwill0956          pcmasterrace   \n",
       "3         shermont  RocketLeagueExchange   \n",
       "4  PandaBearShenyu                 ffxiv   \n",
       "\n",
       "                                                body  TOXICITY  PROFANITY  \\\n",
       "0  Those eyes! I don't think I've ever seen a spi...       2.0        1.0   \n",
       "1        I didn't even catch on... Lmao god damn it.       8.0        9.0   \n",
       "2                                     I'll take it\\n       1.0        0.0   \n",
       "3  What's ur gt il send a friend req... n il let ...       5.0        4.0   \n",
       "4  You.... should not be losing stacks to ES even...       3.0        2.0   \n",
       "\n",
       "   SEXUALLY_EXPLICIT                                          processed  \n",
       "0                3.0  those ey i dont think iv ever seen spider ey l...  \n",
       "1                2.0                   i didnt even catch lmao god damn  \n",
       "2                1.0                                                ill  \n",
       "3                3.0      what ur gt send friend req let kno still moro  \n",
       "4                3.0  you lose stack es even run back forth without ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     56\n",
       "2.0     14\n",
       "0.0     13\n",
       "4.0      4\n",
       "9.0      4\n",
       "3.0      3\n",
       "8.0      2\n",
       "7.0      2\n",
       "5.0      1\n",
       "10.0     1\n",
       "Name: TOXICITY, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirms range of values for labels\n",
    "scored_tweets['TOXICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df=scored_tweets, feature='processed', label='TOXICITY'):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    train_data, test_data = train_test_split(df, test_size=0.25, random_state=7)\n",
    "    X_train, X_test = np.asarray(train_data['processed']), np.asarray(test_data['processed'])\n",
    "    y_train, y_test = np.asarray(train_data[label]), np.asarray(test_data[label])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(df=scored_tweets, feature='processed', label='TOXICITY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(X_train, X_test):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    test_tfidf = vectorizer.transform(X_test)\n",
    "    \n",
    "    return train_tfidf, test_tfidf, vectorizer\n",
    "\n",
    "train_tfidf, test_tfidf, vectorizer = TFIDF(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open('PerspectiveAPI_vectorizer.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25x655 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 117 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:31:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(label='PROFANITY')\n",
    "\n",
    "tweet = 'fuck'\n",
    "processed_punc = re.sub('[^@a-zA-Z ]', '', tweet)  # remove punctuation\n",
    "processed = re.sub('https\\S+|@\\S+|\\b\\w{,1}\\b', '', processed_punc)  # remove https, usernames, len(word) < 1\n",
    "words = word_tokenize(processed)\n",
    "tokens_without_sw = [word for word in words if not word in stopwords.words()]\n",
    "sentence = ' '.join(tokens_without_sw)\n",
    "stemmed_sentence = p.stem_sentence(sentence)\n",
    "t = stemmed_sentence\n",
    "\n",
    "print(t)\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_tfidf = vectorizer.fit_transform(X_train)\n",
    "test_tfidf = vectorizer.transform([t])\n",
    "                                 \n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(train_tfidf, y_train)\n",
    "\n",
    "y_pred = model.predict(test_tfidf)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost_Classifier(feature_category):\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_data(label=feature_category)\n",
    "    train_tfidf, test_tfidf, _ = TFIDF(X_train, X_test)\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "    model.fit(train_tfidf, y_train)\n",
    "    \n",
    "    y_pred = model.predict(test_tfidf)\n",
    "    acc = accuracy_score(y_pred, y_test)\n",
    "    \n",
    "    return (acc, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:31:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.44,\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "               gamma=0, gpu_id=-1, importance_type=None,\n",
       "               interaction_constraints='', learning_rate=0.300000012,\n",
       "               max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "               monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "               num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "               subsample=1, tree_method='exact', validate_parameters=1,\n",
       "               verbosity=None))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_results = XGBoost_Classifier('TOXICITY')\n",
    "toxicity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(toxicity_results[1], open('toxicity_xgb.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:31:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.48,\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "               gamma=0, gpu_id=-1, importance_type=None,\n",
       "               interaction_constraints='', learning_rate=0.300000012,\n",
       "               max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "               monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "               num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "               subsample=1, tree_method='exact', validate_parameters=1,\n",
       "               verbosity=None))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profanity_results = XGBoost_Classifier('PROFANITY')\n",
    "profanity_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(profanity_results[1], open('profanity_xgb.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:31:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.48,\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "               gamma=0, gpu_id=-1, importance_type=None,\n",
       "               interaction_constraints='', learning_rate=0.300000012,\n",
       "               max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "               monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "               num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "               subsample=1, tree_method='exact', validate_parameters=1,\n",
       "               verbosity=None))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sexually_explicit_results = XGBoost_Classifier('SEXUALLY_EXPLICIT')\n",
    "sexually_explicit_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(sexually_explicit_results[1], open('sexually_explicit_xgb.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
